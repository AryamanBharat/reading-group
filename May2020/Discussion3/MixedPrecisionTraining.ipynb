{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MixedPrecisionTraining.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "540b2c1c48124ac3b56e5ce79573336d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8cc783fc16054dd89b78512f736fd630",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44be381862b443fb91adfc01186b08ec",
              "IPY_MODEL_71268643c9a24622a5a3a8cc8cbc18bd"
            ]
          }
        },
        "8cc783fc16054dd89b78512f736fd630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44be381862b443fb91adfc01186b08ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27fd3421b1dc4b828fa5fe556692d187",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea5d88ba687147f58cc0c291fc035bd7"
          }
        },
        "71268643c9a24622a5a3a8cc8cbc18bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95e38818fec54d5491f736f85d18056a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 744kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b504ef6c5bb4f87a1a7ec7b17dc6fdd"
          }
        },
        "27fd3421b1dc4b828fa5fe556692d187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea5d88ba687147f58cc0c291fc035bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95e38818fec54d5491f736f85d18056a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b504ef6c5bb4f87a1a7ec7b17dc6fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28279b292f684bc28442696e33c57a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_732aa72f87424df0af076d3ca870b726",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86d7577cd49449138dceffe74476d660",
              "IPY_MODEL_84fb97e6199d41509a1e3da17b94c4fb"
            ]
          }
        },
        "732aa72f87424df0af076d3ca870b726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d7577cd49449138dceffe74476d660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_392356a136564cbbabee12a70dc29a48",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 254728,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 254728,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13d252714c834fab8607848346e3ffa7"
          }
        },
        "84fb97e6199d41509a1e3da17b94c4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6483c1005ff44b33aa065b138880d228",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 255k/255k [00:00&lt;00:00, 427kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_433b3d25df9a47ae94648229964c63db"
          }
        },
        "392356a136564cbbabee12a70dc29a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13d252714c834fab8607848346e3ffa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6483c1005ff44b33aa065b138880d228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "433b3d25df9a47ae94648229964c63db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsgiitr/reading-group/blob/master/May2020/Discussion3/MixedPrecisionTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v7Patlq86Mbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "78bbdcfc-82fa-45ff-c7df-61a252ecb8cd"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "!pip install tokenizers\n",
        "from tokenizers import BertWordPieceTokenizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPOVl-Aw8EXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "3366e161-b861-452f-bd73-42022795d731"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKJ-J_CV8FyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "path=os.path.join('/content','drive','My Drive','Colab Notebooks','MT_Dataset')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbAsTCX16l5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file1=open(os.path.join(path,'train.en'),'r')\n",
        "file2=open(os.path.join(path,'train.de'),'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnuPH6Cd6l5y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "1d5bd350-19f6-4610-916c-6a08b4c29260"
      },
      "source": [
        "len(file2.read().split('\\n'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJvZf6J76l52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "92eb47b4-449e-40c0-f9f8-55954c56f0ce"
      },
      "source": [
        "len(file1.read().split('\\n'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZFLz2IR6l56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_linewise_dataset(path):\n",
        "    file=open(path)\n",
        "    return file.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuaOD4D36l5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_path=os.path.join(path,'train.en')\n",
        "german_path=os.path.join(path,'train.de')\n",
        "\n",
        "english_dataset=read_linewise_dataset(english_path)\n",
        "german_dataset=read_linewise_dataset(german_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhTrVxaP6l6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "0e4a79aa-d3e4-4b56-83e3-85bc82424ff3"
      },
      "source": [
        "len(english_dataset),len(german_dataset)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29001, 29001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70O-9bRm6l6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "d6ce96fc-0b68-4e8b-d949-8f1f23a541b8"
      },
      "source": [
        "english_dataset[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Two young, White males are outside near many bushes.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLQ22Gco6l6K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "71b87d93-bf0a-4d71-a025-9a16302e8026"
      },
      "source": [
        "german_dataset[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVOtIM0m6l6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tokenizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpYtzE-_6l6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer=BertWordPieceTokenizer( clean_text=True, handle_chinese_chars=False, strip_accents=True, lowercase=True,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkhdB4rp6l6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvc4aWCa6l6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70,
          "referenced_widgets": [
            "540b2c1c48124ac3b56e5ce79573336d",
            "8cc783fc16054dd89b78512f736fd630",
            "44be381862b443fb91adfc01186b08ec",
            "71268643c9a24622a5a3a8cc8cbc18bd",
            "27fd3421b1dc4b828fa5fe556692d187",
            "ea5d88ba687147f58cc0c291fc035bd7",
            "95e38818fec54d5491f736f85d18056a",
            "2b504ef6c5bb4f87a1a7ec7b17dc6fdd"
          ]
        },
        "outputId": "4ea0ae69-d3c5-4e67-ae52-2b0694e289d9"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer_eng=BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "enc=tokenizer_eng.encode(\"Hello There\")\n",
        "\n",
        "dec=tokenizer_eng.decode(enc)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540b2c1c48124ac3b56e5ce79573336d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9J1eWwO6l6c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "5bc6cd39-c36e-4d9a-b9db-6f9bf722ee7f"
      },
      "source": [
        "enc,dec"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([101, 7592, 2045, 102], '[CLS] hello there [SEP]')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upqGOMRu6l6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70,
          "referenced_widgets": [
            "28279b292f684bc28442696e33c57a8b",
            "732aa72f87424df0af076d3ca870b726",
            "86d7577cd49449138dceffe74476d660",
            "84fb97e6199d41509a1e3da17b94c4fb",
            "392356a136564cbbabee12a70dc29a48",
            "13d252714c834fab8607848346e3ffa7",
            "6483c1005ff44b33aa065b138880d228",
            "433b3d25df9a47ae94648229964c63db"
          ]
        },
        "outputId": "a61efa2f-9630-43a4-e406-e1cf51f021ea"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer_ger=BertTokenizer.from_pretrained(\"bert-base-german-cased\",\n",
        "                                       special_tokens=[\"[PAD]\", \"[UNK]\", \"[SOS]\", \"[EOS]\", \"[MASK]\"])\n",
        "enc=tokenizer_ger.encode(\"Zwei junge weiÃŸe MÃ¤nner sind im Freien in der NÃ¤he vieler BÃ¼sche.\")\n",
        "\n",
        "dec=tokenizer_ger.decode(enc)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28279b292f684bc28442696e33c57a8b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=254728.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK3rrnjB6l6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset_nopadded:\n",
        "    def __init__(self,sent_eng,sent_ger,tokenizer_eng,tokenizer_ger):\n",
        "        self.sent_eng=sent_eng\n",
        "        self.sent_ger=sent_ger\n",
        "        self.tokenize_eng=tokenizer_eng\n",
        "        self.tokenize_ger=tokenizer_ger\n",
        "        \n",
        "        self.processed_data_eng=[]\n",
        "        self.processed_data_ger=[]\n",
        "        \n",
        "        for i in range(len(self.sent_eng)):\n",
        "            self.processed_data_eng.append(self.tokenize_eng.encode(self.sent_eng[i]))   \n",
        "            self.processed_data_ger.append(self.tokenize_ger.encode(self.sent_ger[i]))\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.sent_eng)\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        sample=[torch.tensor(self.processed_data_eng[item]),torch.tensor(self.processed_data_ger[item])]\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPxgjaP6l6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=Dataset_nopadded(english_dataset,\n",
        "                german_dataset,\n",
        "               tokenizer_eng,\n",
        "               tokenizer_ger)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpzUA9b36l6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_eng={}\n",
        "vocab_ger={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eILnlaf16l6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_collate(batch):\n",
        "    \n",
        "    (xx, yy) = zip(*batch)\n",
        "\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    y_lens = [len(y) for y in yy]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
        "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
        "\n",
        "    return xx_pad, yy_pad, x_lens, y_lens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYQkBYLb6l6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "data_loader = DataLoader(dataset=dataset, batch_size=128, shuffle=True, collate_fn=pad_collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs79CK1K6l6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "51ab8904-933c-44ec-99ef-8380968d7735"
      },
      "source": [
        "len(tokenizer_eng.vocab)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az0Y1pNf6l62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True,batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "      \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "  \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len,batch_first=True,enforce_sorted=False)\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "              \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs,batch_first=True) \n",
        "      \n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUSzigOG6l64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[0]\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "        \n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQy1oQ16l67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs,mask)\n",
        "      \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "\n",
        "        embedded=embedded.squeeze(2)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "\n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4JmcNCP6l6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder.to(device)\n",
        "        self.decoder = decoder.to(device)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx)\n",
        "        return mask\n",
        "    \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        outputs = torch.zeros(batch_size,trg_len,trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "\n",
        "        input = trg[:,0:1]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "    \n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs,mask)\n",
        "            \n",
        "            outputs[:,t,:] = output\n",
        "            \n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            top1 = torch.max(output,1)[1] \n",
        "\n",
        "            input = trg[:,t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_8xZ--U6l7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "306c2fd7-dd19-41da-fa9a-799a64924ee5"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC97Y19y6l7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim=len(tokenizer_eng.vocab)\n",
        "output_dim=len(tokenizer_ger.vocab)\n",
        "\n",
        "enc_emb_dim=50\n",
        "dec_emb_dim=50\n",
        "\n",
        "enc_hid_dim=100\n",
        "dec_hid_dim=100\n",
        "\n",
        "enc_dropout=0.3\n",
        "dec_dropout=0.3\n",
        "\n",
        "output_pad=0 \n",
        "attention = Attention(enc_hid_dim, dec_hid_dim)\n",
        "enc = Encoder(input_dim, enc_emb_dim, enc_hid_dim, dec_hid_dim, enc_dropout)\n",
        "dec = Decoder(output_dim, dec_emb_dim, enc_hid_dim, dec_hid_dim, dec_dropout, attention)\n",
        "\n",
        "\n",
        "model = Seq2Seq(enc, dec, output_pad, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfVZPvpS6l7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "353d355a-b9a3-4bc0-e323-5df663e579d7"
      },
      "source": [
        "model"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(30522, 50)\n",
              "    (rnn): GRU(50, 100, batch_first=True, bidirectional=True)\n",
              "    (fc): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=300, out_features=100, bias=True)\n",
              "      (v): Linear(in_features=100, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(30000, 50)\n",
              "    (rnn): GRU(250, 100)\n",
              "    (fc_out): Linear(in_features=350, out_features=30000, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7y3Xiak6l7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "b801fb6f-7b20-4428-b0c6-d8644845c9b1"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(30522, 50)\n",
              "    (rnn): GRU(50, 100, batch_first=True, bidirectional=True)\n",
              "    (fc): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=300, out_features=100, bias=True)\n",
              "      (v): Linear(in_features=100, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(30000, 50)\n",
              "    (rnn): GRU(250, 100)\n",
              "    (fc_out): Linear(in_features=350, out_features=30000, bias=True)\n",
              "    (dropout): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYrtQaxM6l7Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "a91c6562-7439-4026-f12a-d7929069ad32"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,803,200 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzSFkJZ96l7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWOLJZKv6l7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = output_pad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eViMmSf6l7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDhuviiR6l7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f31eb3f2-dc57-4a22-fcd4-48af307846d1"
      },
      "source": [
        "for batch,lens in enumerate(data_loader):\n",
        "    \n",
        "    print(f\"Input Shape {lens[0].shape}\")\n",
        "    print(f\"Output Shape {lens[1].shape}\")\n",
        "    print(f\"Input Length {len(lens[2])}\")\n",
        "    print(f\"Output Length {len(lens[3])}\")\n",
        "\n",
        "    break"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Shape torch.Size([128, 43])\n",
            "Output Shape torch.Size([128, 44])\n",
            "Input Length 128\n",
            "Output Length 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v18Cg_Wb6l7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch[0].to(device)\n",
        "        src_len=batch[2]\n",
        "        trg = batch[1].to(device)\n",
        "        trg_len=batch[3]\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0fMMTPr26l7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "c17fedab-a3c6-424f-ec90-5d5d0a2ce2ab"
      },
      "source": [
        "train_loss=train(model, data_loader, optimizer, criterion, 1)\n",
        "print(train_loss)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.6702994817154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leh5bAXk_-it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), os.path.join(path,'WithoutMPT_Model'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ2uVXwe6l7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training with Mixed precision on Pytorch means training with autocast and Grad scalaer together"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "t_lv4BNj6l7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install apex\n",
        "from torch.cuda.amp import autocast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyo3ib8ZBm_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDkhtwjz6l73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with autocast_():\n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch[0]\n",
        "            src_len=batch[2]\n",
        "            trg = batch[1]\n",
        "            trg_len=batch[3]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(src, src_len, trg)\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            #updates the Scale for next iteration\n",
        "            scaler.update()\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF9KO9yw_y93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "0d6b1b4c-dce4-4b3f-f3d0-8d1733802632"
      },
      "source": [
        "train_loss=train(model, data_loader, optimizer, criterion, 1)\n",
        "print(train_loss)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-344c4014186a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-f1d2f5d0d352>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mautocast_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'func'"
          ]
        }
      ]
    }
  ]
}