
# ADVERSARIAL EXAMPLES
## Paper
### [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)
## Abstract
Neural networks have demonstrated robust
performance in several computer vision tasks with
new algorithms reported to even surpass human
performance. But the latest studies have also shown
that such networks are defenseless when it comes to
the attacks of adversarial examples
Adversarial examples are inputs to a neural network
that result in an incorrect output from the network.

# Supplementary Material
1. [Adversarial ML Tutorial](https://adversarial-ml-tutorial.org/)
2. [Generative Adversarial Networks Challenges, Solutions and Future Directions](https://arxiv.org/abs/2005.00065)
3. [DCGAN Tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)
4. [Adversarial Tutorial](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)
5. [Tricking Neural Network](https://medium.com/@ml.at.berkeley/tricking-neural-networks-create-your-own-adversarial-examples-a61eb7620fd8)
# Reference
```
@misc{goodfellow2014explaining,
    title={Explaining and Harnessing Adversarial Examples},
    author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
    year={2014},
    eprint={1412.6572},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
```
