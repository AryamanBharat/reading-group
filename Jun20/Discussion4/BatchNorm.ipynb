{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchNorm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcUvW6M4PEb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snxrmeejPNpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define Hyper-parameters \n",
        "input_size = 784\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.006"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87CovAnEPaPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80i15LaRPoks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fully connected neural network\n",
        "#using nn.Batchnorm directly provided by pytorch\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.bn2  = nn.BatchNorm1d(hidden_size)\n",
        "        self.fc3 =  nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnL8t5jhQAAe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "f951fe9b-f0ac-43e2-a0f4-c167298b4ae4"
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backprpagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in test_loader:\n",
        "                    images = images.reshape(-1, 28*28).to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in train_loader:\n",
        "                    images = images.reshape(-1, 28*28).to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Accuracy of the network on the 60000 train images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.2421\n",
            "Accuracy of the network on the 10000 test images: 93.53 %\n",
            "Accuracy of the network on the 60000 train images: 93.45833333333333 %\n",
            "Epoch [1/2], Step [200/600], Loss: 0.2424\n",
            "Accuracy of the network on the 10000 test images: 94.36 %\n",
            "Accuracy of the network on the 60000 train images: 94.68666666666667 %\n",
            "Epoch [1/2], Step [300/600], Loss: 0.1210\n",
            "Accuracy of the network on the 10000 test images: 95.07 %\n",
            "Accuracy of the network on the 60000 train images: 95.59 %\n",
            "Epoch [1/2], Step [400/600], Loss: 0.2766\n",
            "Accuracy of the network on the 10000 test images: 95.85 %\n",
            "Accuracy of the network on the 60000 train images: 96.22666666666667 %\n",
            "Epoch [1/2], Step [500/600], Loss: 0.0599\n",
            "Accuracy of the network on the 10000 test images: 96.31 %\n",
            "Accuracy of the network on the 60000 train images: 97.02 %\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1392\n",
            "Accuracy of the network on the 10000 test images: 96.09 %\n",
            "Accuracy of the network on the 60000 train images: 96.89 %\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1616\n",
            "Accuracy of the network on the 10000 test images: 96.36 %\n",
            "Accuracy of the network on the 60000 train images: 97.36 %\n",
            "Epoch [2/2], Step [200/600], Loss: 0.0708\n",
            "Accuracy of the network on the 10000 test images: 96.85 %\n",
            "Accuracy of the network on the 60000 train images: 97.71833333333333 %\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0507\n",
            "Accuracy of the network on the 10000 test images: 96.79 %\n",
            "Accuracy of the network on the 60000 train images: 97.72166666666666 %\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0752\n",
            "Accuracy of the network on the 10000 test images: 96.72 %\n",
            "Accuracy of the network on the 60000 train images: 97.99333333333334 %\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1189\n",
            "Accuracy of the network on the 10000 test images: 96.83 %\n",
            "Accuracy of the network on the 60000 train images: 97.98666666666666 %\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0574\n",
            "Accuracy of the network on the 10000 test images: 96.78 %\n",
            "Accuracy of the network on the 60000 train images: 97.98166666666667 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gILi_38Qmqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now doing the same but using custom Batch norm class\n",
        "class CustomBatchNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, in_size, momentum=0.9, eps = 1e-5):\n",
        "        super(CustomBatchNorm, self).__init__()\n",
        "        \n",
        "        self.momentum = momentum\n",
        "        self.insize = in_size\n",
        "        self.eps = eps\n",
        "        \n",
        "        self.gamma = nn.Parameter(torch.FloatTensor(self.insize).uniform_())\n",
        "        self.beta = nn.Parameter(torch.zeros(self.insize))\n",
        "            \n",
        "        self.register_buffer('running_mean', torch.zeros(self.insize))\n",
        "        self.register_buffer('running_var', torch.ones(self.insize))\n",
        "        \n",
        "        self.running_mean.zero_()\n",
        "        self.running_var.fill_(1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \n",
        "        X = input\n",
        "\n",
        "        if len(X.shape) not in (2, 4):\n",
        "            raise ValueError(\"only support dense or 2dconv\")\n",
        "        \n",
        "        # dense layer\n",
        "        elif len(X.shape) == 2:\n",
        "            if self.training:\n",
        "                mean = torch.mean(X, axis=0)\n",
        "                variance = torch.mean((X-mean)**2, axis=0)\n",
        "                \n",
        "                self.running_mean = (self.momentum * self.running_mean) + (1.0-self.momentum) * mean\n",
        "                self.running_var = (self.momentum * self.running_var) + (1.0-self.momentum) * (input.shape[0]/(input.shape[0]-1)*variance)\n",
        "            \n",
        "            else:\n",
        "                mean = self.running_mean\n",
        "                variance = self.running_var\n",
        "                \n",
        "            X_hat = (X-mean) * 1.0 /torch.sqrt(variance + self.eps)\n",
        "            out = self.gamma * X_hat + self.beta\n",
        "  \n",
        "\t\t\t\t# convolutional layer\n",
        "        elif len(X.shape) == 4:\n",
        "            if self.training:\n",
        "                N, C, H, W = X.shape\n",
        "                mean = torch.mean(X, axis = (0, 2, 3))\n",
        "                variance = torch.mean((X - mean.reshape((1, C, 1, 1))) ** 2, axis=(0, 2, 3))\n",
        "                \n",
        "                self.running_mean = (self.momentum * self.running_mean) + (1.0-self.momentum) * mean\n",
        "                self.running_var = (self.momentum * self.running_var) + (1.0-self.momentum) * (input.shape[0]/(input.shape[0]-1)*variance)\n",
        "            else:\n",
        "                mean = self.running_mean\n",
        "                var = self.running_var\n",
        "                \n",
        "            X_hat = (X - mean.reshape((1, C, 1, 1))) * 1.0 / torch.sqrt(variance.reshape((1, C, 1, 1)) + self.eps)\n",
        "            out = self.gamma.reshape((1, C, 1, 1)) * X_hat + self.beta.reshape((1, C, 1, 1))\n",
        "        \n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNbyXtPqRcWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BnNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(BnNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.bn1 = CustomBatchNorm(hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.bn2  = CustomBatchNorm(hidden_size)\n",
        "        self.fc3 =  nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "model2 = BnNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate)  \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWRo-zb9SF1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "b6648f50-63ca-4fb9-c8fc-e50220765f48"
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model2(images)\n",
        "        loss = criterion2(outputs, labels)\n",
        "        \n",
        "        # Backprpagation and optimization\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in test_loader:\n",
        "                    images = images.reshape(-1, 28*28).to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model2(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in train_loader:\n",
        "                    images = images.reshape(-1, 28*28).to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    outputs = model2(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                print('Accuracy of the network on the 60000 train images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.2948\n",
            "Accuracy of the network on the 10000 test images: 92.73 %\n",
            "Accuracy of the network on the 60000 train images: 92.195 %\n",
            "Epoch [1/2], Step [200/600], Loss: 0.1432\n",
            "Accuracy of the network on the 10000 test images: 94.27 %\n",
            "Accuracy of the network on the 60000 train images: 94.34166666666667 %\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2694\n",
            "Accuracy of the network on the 10000 test images: 95.37 %\n",
            "Accuracy of the network on the 60000 train images: 95.76 %\n",
            "Epoch [1/2], Step [400/600], Loss: 0.1553\n",
            "Accuracy of the network on the 10000 test images: 95.75 %\n",
            "Accuracy of the network on the 60000 train images: 96.35 %\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1210\n",
            "Accuracy of the network on the 10000 test images: 96.29 %\n",
            "Accuracy of the network on the 60000 train images: 96.92333333333333 %\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1328\n",
            "Accuracy of the network on the 10000 test images: 96.31 %\n",
            "Accuracy of the network on the 60000 train images: 97.10333333333334 %\n",
            "Epoch [2/2], Step [100/600], Loss: 0.0873\n",
            "Accuracy of the network on the 10000 test images: 96.66 %\n",
            "Accuracy of the network on the 60000 train images: 97.365 %\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1049\n",
            "Accuracy of the network on the 10000 test images: 96.66 %\n",
            "Accuracy of the network on the 60000 train images: 97.44166666666666 %\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0890\n",
            "Accuracy of the network on the 10000 test images: 96.58 %\n",
            "Accuracy of the network on the 60000 train images: 97.665 %\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0732\n",
            "Accuracy of the network on the 10000 test images: 96.84 %\n",
            "Accuracy of the network on the 60000 train images: 97.485 %\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1347\n",
            "Accuracy of the network on the 10000 test images: 96.54 %\n",
            "Accuracy of the network on the 60000 train images: 97.86166666666666 %\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0786\n",
            "Accuracy of the network on the 10000 test images: 96.93 %\n",
            "Accuracy of the network on the 60000 train images: 97.96333333333334 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AUTqJDrWGtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}